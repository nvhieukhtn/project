{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Tiêu đề   : Bài tập cá nhân 02\n",
    "    Họ và tên : Nguyễn Văn Hiếu\n",
    "    MSSV      : 1412166\n",
    "    Phiên bản : Python 2.7\n",
    "\n",
    "## Xây dựng  thuật toán cây quyết định cho bài toán phân lớp với tập dữ liệu iris\n",
    "1. Xấy dựng các lớp đối tượng\n",
    "    - Lớp $\\color{red}{Node}$:\n",
    "        - Lưu giá trị tại một nút trên cây quyết định\n",
    "        - Tại mỗi Node có một thuộc tính feature\n",
    "        - Mỗi Node có hoặc nhiều đối tượng Branch\n",
    "    - Lớp $\\color{red}{Branch}$: \n",
    "        - Lưu các nhánh đi tại một nút\n",
    "        - Mỗi Branch gồm có một giá trị value là giá trị tại nút đó, và nút con kiểu Node\n",
    "    - Lớp $\\color{red}{DecisionTree}$ bao gồm:\n",
    "        - Các hàm tạo cây quyết định\n",
    "        - Các hàm kiểm tra độ chính xác của cây quyết định đã tạo\n",
    "2. Xây dựng cây quyết định\n",
    "    - $Entropy = \\sum\\limits_{i = 1}^{c}(-p_ilog_2p_i)$ là hàm để đo độ thuần của tập train\n",
    "    - $Gain(S,A) = \\sum\\limits_{v \\in values(A)}{{\\mid{S_v}\\mid}\\over{\\mid{S_v}\\mid}}$ là hàm kết hợp hàm Entropy để đơn giản hóa cây quyết định\n",
    "    - Hàm Best-Split: Tìm ra được trường thuộc tính có độ lợi nhỏ nhất để chia\n",
    "           Input: Tập dữ liệu và tập thuộc tính\n",
    "           Ouput: Thuộc tính chia có lợi nhất\n",
    "           **************************************\n",
    "```python\n",
    "def Best_Split(Data,F):\n",
    "    min_gain = 1;\n",
    "    for f in F:\n",
    "        if(Gain(data,f) < min_gain):\n",
    "            min_gain = Gain(data,f)\n",
    "            best_split = f\n",
    "    return best_split\n",
    "```\n",
    "    - Thuật toán ID3\n",
    "```python\n",
    "def GrowTree(D,F):\n",
    "   if(Homogeneous(D)): #Kiểm tra lớp đã được phân hay chưa\n",
    "       return Label(D) #Trả về nhãn của Target\n",
    "   S = Best-Split(D)\n",
    "   for data in dataCollection: # dataCollection là data bị chia bởi S\n",
    "       if(data != NULL):\n",
    "           T = GrowTree(data,F)\n",
    "       else:\n",
    "           return Label(D)\n",
    "   return S #Với các cây con T\n",
    "```\n",
    "### Một số hàm quan trọng\n",
    "\n",
    "```python\n",
    "def ConvertDataset(D): #Chuyển dữ liệu từ số thực sang giá trị rời rạc\n",
    "def GetTarget(D): #Từ cây quyết định đã tạo và tập dữ liệu cho vào xác định lớp của nó\n",
    "```\n",
    "3. Chuẩn hóa dữ liệu Iris\n",
    "    - Tập dữ liệu Iris có dạng :\n",
    "    \n",
    "|Sepal length|Sepal width|Petal length|Petal width|Class|\n",
    "|:----------:|:---------:|:----------:|:---------:|:---:|\n",
    "|     R      |     R     |     R      |     R     |Text |\n",
    "\n",
    "    - Với các trường là số thực, vì vậy ta cần chuyển các trường đó thành dữ liệu rời rạc\n",
    "    \n",
    "|Sepal length|Sepal width|Petal length|Petal width|\n",
    "|:----------:|:---------:|:----------:|:---------:|\n",
    "|>5.95       |>3.1       |>2.5        |>1.75      |\n",
    "|4.95<x<=5.95|3.05<x<=3.1|<= 2.5      |<=1.75     |\n",
    "|<4.95       |<3.05      | \n",
    "\n",
    "\n",
    "4. Tập dữ liệu\n",
    "    - Dữ liệu train\n",
    "        - Sử dụng 50% dữ liệu iris để train. Lấy các row chẵn để train (0,2,4,...,148)\n",
    "    - Dữ liệu test\n",
    "        - Sử dụng 50% dữ liệu iris còn lại để test. Lấy các row lẻ để test (1,3,5,..,149)\n",
    "5. Kết quả \n",
    "    - Training\n",
    "        - Đúng 73/75 bộ mẫu. 2 mẫu sai.\n",
    "        - Độ chính xác 97%\n",
    "    - Testing\n",
    "        - Đúng 72/75 bộ mẫu\n",
    "        - Độ chính xác 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('So tap sai khi Training : ', 2, 'Tong so tap : ', 75)\n",
      "('Do chinh xac : ', 97.0, '%')\n",
      "('So tap sai khi Testing : ', 3, '.Tong so tap : ', 75)\n",
      "('Do chinh xac : ', 96.0, '%')\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class Branch:\n",
    "    def __init__(self, val, chil):\n",
    "        self.value = val\n",
    "        self.child = chil\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, c):\n",
    "        self.category = c\n",
    "        self.branch = []\n",
    "    def AddBranch(self,way):\n",
    "        self.branch.append(way)\n",
    "    def IsLeaf(self):\n",
    "        if len(self.branch) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.ErrorCount = 0\n",
    "    def Entropy(self, data,feature,value):\n",
    "        valueEntropy = 0.0\n",
    "        subData = data[data[feature] == value]\n",
    "        num_records = len(subData)\n",
    "        num_categories = subData[target].value_counts()\n",
    "        coeffident = [x for x in num_categories]\n",
    "        for x in coeffident:\n",
    "            temp = float(x)/num_records\n",
    "            valueEntropy += (-1) * temp * math.log(temp, 2)\n",
    "        return valueEntropy\n",
    "    def Gain(self, data,feature):\n",
    "        dataGain = 0.0\n",
    "        num_records = len(data)\n",
    "        subData = data[[feature, target]].groupby(feature).count()\n",
    "        for category in subData.index:\n",
    "            count_category = float(len(data[data[feature] == category]))\n",
    "            dataGain += (count_category / num_records) * self.Entropy(data, feature, category)\n",
    "        return dataGain\n",
    "    def Homogeneous(self, data):\n",
    "        if(len(data.columns) == 1):\n",
    "            return True\n",
    "        categories = data[target].value_counts()\n",
    "        if (len(categories) == 1):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def Label(self, data):\n",
    "        max_value = 0\n",
    "        subData = data[[target]].groupby(target).count().index\n",
    "        for result in subData:\n",
    "            if len(data[data[target] == result]) > max_value:\n",
    "                max_value = len(data[data[target] == result])\n",
    "                leaf = result\n",
    "        self.ErrorCount += len(data) - max_value\n",
    "        leaf = Node(leaf)\n",
    "        return leaf\n",
    "    def BestSplit(self, data, features):\n",
    "        min_gain = 1000\n",
    "        for feature in features:\n",
    "            gain = self.Gain(data, feature)\n",
    "            if (gain < min_gain):\n",
    "                min_gain = gain\n",
    "                best_feature = feature\n",
    "        return best_feature\n",
    "\n",
    "    def GrowTree(self, data, features):\n",
    "        if self.Homogeneous(data):\n",
    "            return self.Label(data)\n",
    "        best_feature = self.BestSplit(data, features)\n",
    "        root = Node(best_feature)\n",
    "        value_of_features = data[best_feature].value_counts().index.values\n",
    "        for value in value_of_features:\n",
    "            subData = data[data[best_feature] == value].drop(best_feature, axis=1)\n",
    "            num_subcolumns = len(subData.columns)\n",
    "            subFeatures = subData.columns[:num_subcolumns - 1]\n",
    "            node = self.GrowTree(subData, subFeatures)\n",
    "            way = Branch(value, node)\n",
    "            root.AddBranch(way)\n",
    "        return root\n",
    "    def MakeTree(self,data,features):\n",
    "        self.Tree = self.GrowTree(data,features)\n",
    "        return self.ErrorCount\n",
    "    def GetTarget(self,data_row):\n",
    "        tmpTree = self.Tree\n",
    "        while tmpTree.IsLeaf() == False:\n",
    "            for val in tmpTree.branch:\n",
    "                if len(data_row[data_row[tmpTree.category] == val.value]) > 0:\n",
    "                    tmpTree = val.child\n",
    "                    break\n",
    "        return tmpTree.category\n",
    "    def Test(self,data_test):\n",
    "        self.ErrorCount = 0\n",
    "        num_records = len(data_test)\n",
    "        for i in range(num_records):\n",
    "            data_row = data_test.iloc[[i]]\n",
    "            result = self.GetTarget(data_row)\n",
    "            if len(data_row[data_row[target] == result]) == 0:\n",
    "                self.ErrorCount += 1\n",
    "        return self.ErrorCount\n",
    "def convertData(data,features):\n",
    "    data.loc[data[features[0]] > 5.95,features[0]] = 'Sepal length > 5.95'\n",
    "    data.loc[data[features[0]] <= 5.95,features[0]] = '4.95 < Sepal length <= 5.95'\n",
    "    data.loc[data[features[0]] <= 4.95,features[0]] = 'Sepal length <= 4.95'\n",
    "\n",
    "    data.loc[data[features[1]] > 3.1,features[1]] = 'Sepal width > 3.1'\n",
    "    data.loc[data[features[1]] <= 3.1, features[1]] = '3.05 < Sepal width <= 3.1'\n",
    "    data.loc[data[features[1]] <= 3.05, features[1]] = 'Sepal width <= 3.05'\n",
    "\n",
    "    data.loc[data[features[2]] > 2.5, features[2]] = 'Petal length > 2.5'\n",
    "    data.loc[data[features[2]] <= 2.5, features[2]] = 'Petal length <= 2.5'\n",
    "\n",
    "    data.loc[data[features[3]] > 1.75,   features[3]] = 'Petal Width > 1.75'\n",
    "    data.loc[data[features[3]] <= 1.75, features[3]] = 'Petal Width <= 1.75'\n",
    "    return data\n",
    "#Main function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',header=None)\n",
    "data.columns = [\"Sepal length\",\"Sepal width\",\"Petal length\",\"Petal width\",\"Class\"]\n",
    "target = \"Class\"\n",
    "num_columns = len(data.columns) - 1\n",
    "features = data.columns[:num_columns]\n",
    "data = convertData(data,features)\n",
    "num_columns = len(data.columns) - 1\n",
    "features = data.columns[:num_columns]\n",
    "data_train = data[0:150:2]\n",
    "data_test = data[1:150:2]\n",
    "\n",
    "decisionTree = DecisionTree()\n",
    "ErrorCount_Training = decisionTree.MakeTree(data_train,features)\n",
    "print(\"So tap sai khi Training : \",ErrorCount_Training, \"Tong so tap : \" ,len(data_train))\n",
    "print(\"Do chinh xac : \",float(100*(len(data_train) - ErrorCount_Training )/ len(data_train)),\"%\")\n",
    "\n",
    "ErrorCount_Testing = decisionTree.Test(data_test)\n",
    "print(\"So tap sai khi Testing : \",ErrorCount_Testing,'.Tong so tap : ',len(data_test))\n",
    "print(\"Do chinh xac : \",float(100*(len(data_test) - ErrorCount_Testing )/ len(data_test)),\"%\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
